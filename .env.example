# =============================================================================
# HyperMatrix v2026.01 - Configuracion de Entorno
# =============================================================================
# Copia este archivo a .env y ajusta los valores segun tu sistema
#
# cp .env.example .env
# =============================================================================

# === RUTA DE PROYECTOS A ANALIZAR ===
PROJECTS_PATH=E:/MIS_PROYECTOS

# =============================================================================
# PROVEEDOR DE IA
# =============================================================================
# Opciones: ollama | openai | anthropic | groq
#
# - ollama:    IA local (gratis, privado, requiere GPU para velocidad)
# - openai:    GPT-4o, GPT-4o-mini (rapido, ~$0.01-0.03/consulta)
# - anthropic: Claude 3 Haiku/Sonnet (rapido, ~$0.01-0.02/consulta)
# - groq:      Llama 3, Mixtral (MUY rapido, ~$0.001/consulta)

AI_PROVIDER=ollama

# =============================================================================
# OLLAMA LOCAL (si AI_PROVIDER=ollama)
# =============================================================================
OLLAMA_MODEL=openhermes:latest

# Modelos recomendados para tu RTX 3060 12GB:
#   - openhermes:latest    (7B, rapido, bueno para codigo)
#   - mistral:7b           (7B, equilibrado)
#   - codellama:7b         (7B, especializado en codigo)
#   - deepseek-coder:6.7b  (6.7B, excelente para codigo)
#   - llama3:8b            (8B, muy capaz)
#   - codellama:13b        (13B, mejor calidad, mas lento)

# Paralelismo de Ollama (peticiones simultaneas)
OLLAMA_NUM_PARALLEL=2

# =============================================================================
# OPENAI (si AI_PROVIDER=openai)
# =============================================================================
# Obtener API key: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4o-mini

# Modelos disponibles:
#   - gpt-4o-mini     (rapido, barato, muy bueno)
#   - gpt-4o         (mas potente, mas caro)
#   - gpt-4-turbo    (anterior flagship)

# =============================================================================
# ANTHROPIC (si AI_PROVIDER=anthropic)
# =============================================================================
# Obtener API key: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxx
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Modelos disponibles:
#   - claude-3-haiku-20240307   (rapido, barato)
#   - claude-3-sonnet-20240229  (equilibrado)
#   - claude-3-opus-20240229    (mas potente, mas caro)

# =============================================================================
# GROQ (si AI_PROVIDER=groq) - MUY RAPIDO Y BARATO
# =============================================================================
# Obtener API key: https://console.groq.com/
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxx
GROQ_MODEL=llama-3.1-8b-instant

# Modelos disponibles (todos muy rapidos):
#   - llama-3.1-8b-instant   (rapido, bueno)
#   - llama-3.1-70b-versatile (muy potente)
#   - mixtral-8x7b-32768     (buen equilibrio)
#   - gemma2-9b-it           (Google, compacto)

# =============================================================================
# LIMITES DE RECURSOS (Docker)
# =============================================================================
# Ajusta segun tu CPU. Ejemplo: si tienes 12 nucleos, usa 6 para Ollama

# CPU para Ollama (inferencia IA)
OLLAMA_CPUS=6
OLLAMA_MEMORY=12G

# CPU para HyperMatrix (web server, analisis)
HYPERMATRIX_CPUS=2
HYPERMATRIX_MEMORY=2G

# =============================================================================
# EJEMPLO DE CONFIGURACIONES
# =============================================================================
#
# --- PC Gaming (RTX 3060, 12 cores, 32GB RAM) ---
# AI_PROVIDER=ollama
# OLLAMA_MODEL=openhermes:latest
# OLLAMA_CPUS=6
# OLLAMA_MEMORY=12G
#
# --- Laptop sin GPU (8 cores, 16GB RAM) ---
# AI_PROVIDER=groq
# GROQ_API_KEY=gsk_xxxxx
# GROQ_MODEL=llama-3.1-8b-instant
#
# --- Maxima calidad (con presupuesto) ---
# AI_PROVIDER=openai
# OPENAI_API_KEY=sk-xxxxx
# OPENAI_MODEL=gpt-4o
#
# --- Privacidad maxima (sin internet) ---
# AI_PROVIDER=ollama
# OLLAMA_MODEL=codellama:13b
# =============================================================================
